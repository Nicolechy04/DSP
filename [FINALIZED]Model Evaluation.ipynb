{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1523ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Metadata ---\n",
      "\n",
      "--- EVALUATING AUDIO MODELS ---\n",
      "   Testing Audio_Baseline_CNN..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score: 40.55%\n",
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "   Testing Audio_ResNet50... Score: 16.83%\n",
      "   Testing Audio_CRNN_LSTM... Score: 43.50%\n",
      "   Testing Audio_EfficientNet_Refined... Score: 55.02%\n",
      "   Testing Audio_ResNet50_Augmented_Balanced... Score: 52.95%\n",
      "   Testing Audio_EfficientNet_Balanced... Score: 56.00%\n",
      "\n",
      "--- EVALUATING FACE MODELS ---\n",
      "   Testing Face_Baseline_CNN...Found 1016 validated image filenames belonging to 7 classes.\n",
      " Score: 1.57%\n",
      "   Testing Face_Xception...Found 1016 validated image filenames belonging to 7 classes.\n",
      " Score: 37.50%\n",
      "   Testing Face_ResNet50...Found 1016 validated image filenames belonging to 7 classes.\n",
      " Error: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall/Face_ResNet50_1/conv5_block1_0_conv_1/BiasAdd defined at (most recent call last):\n",
      "<stack traces unavailable>\n",
      "Operation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n",
      "\t [[{{node StatefulPartitionedCall/Face_ResNet50_1/conv5_block1_0_conv_1/BiasAdd}}]] [Op:__inference_multi_step_on_iterator_49218]\n",
      "   Testing efficientnet_improved...Found 1016 validated image filenames belonging to 7 classes.\n",
      " Score: 53.35%\n",
      "   Testing Face_EfficientNet_Balanced...Found 1016 validated image filenames belonging to 7 classes.\n",
      " Score: 56.10%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- 1. IMPORT PREPROCESSING ---\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as res_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess\n",
    "\n",
    "# --- 2. CONFIGURATION & DATA LOADING ---\n",
    "MODEL_DIR = \"models_zoo_1\"\n",
    "DATA_DIR = r\"C:\\Users\\User\\Multimodel AI\\data_1\" \n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(\"--- Loading Metadata ---\")\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test_face.csv\"))\n",
    "test_aud = pd.read_csv(os.path.join(DATA_DIR, \"test_audio.csv\"))\n",
    "\n",
    "# --- 3. FIX: ENCODE LABELS ---\n",
    "le = LabelEncoder()\n",
    "all_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "le.fit(all_labels)\n",
    "\n",
    "test_df['label_str'] = test_df['label'].astype(str)\n",
    "test_df['label_encoded'] = le.transform(test_df['label_str'])\n",
    "\n",
    "test_aud['label_str'] = test_aud['label'].astype(str)\n",
    "test_aud['label_encoded'] = le.transform(test_aud['label_str'])\n",
    "\n",
    "label_column = 'label_str'\n",
    "\n",
    "# --- 4. AUDIO DATA GENERATOR ---\n",
    "class NpyDataGenerator(Sequence):\n",
    "    def __init__(self, df, preprocess_f, batch_size=16, target_size=(224,224), shuffle=False):\n",
    "        self.df = df\n",
    "        self.preprocess_f = preprocess_f\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if hasattr(self, 'shuffle') and self.shuffle: \n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        X, y = [], []\n",
    "        for _, row in batch_df.iterrows():\n",
    "            spec = np.load(row['audio_path'])\n",
    "            # Ensure resize happens first\n",
    "            if spec.shape[:2] != self.target_size:\n",
    "                spec = cv2.resize(spec, self.target_size)\n",
    "            \n",
    "            # Ensure 3 channels\n",
    "            if len(spec.shape) == 2: \n",
    "                spec = np.stack((spec,)*3, axis=-1)\n",
    "            \n",
    "            # Preprocess\n",
    "            X.append(self.preprocess_f(spec.astype(np.float32)))\n",
    "            y.append(tf.keras.utils.to_categorical(row['label_encoded'], 7))\n",
    "            \n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "# --- 5. PREPROCESSING WRAPPERS ---\n",
    "def eff_audio_wrapper(img):\n",
    "    # EfficientNet: Ensure 0-255 range just in case, though it handles scaling internally.\n",
    "    if np.max(img) <= 1.0:\n",
    "        img = img * 255.0\n",
    "    return eff_preprocess(img)\n",
    "\n",
    "def resnet_audio_wrapper(img):\n",
    "    # CRITICAL FIX for ResNet: It requires 0-255 inputs to perform mean subtraction correctly.\n",
    "    # If inputs are 0-1 (common in .npy), we scale them up.\n",
    "    if np.max(img) <= 1.0:\n",
    "        img = img * 255.0\n",
    "    return res_preprocess(img)\n",
    "\n",
    "def get_preprocess_func(model_name, modality):\n",
    "    # 1. Handle Audio Specifics\n",
    "    if modality == \"AUDIO\":\n",
    "        if \"ResNet\" in model_name:\n",
    "            return resnet_audio_wrapper  # Matches 'Audio_ResNet50_Augmented_Balanced'\n",
    "        if \"EfficientNet\" in model_name:\n",
    "            return eff_audio_wrapper\n",
    "\n",
    "    # 2. Handle Face (Image) Specifics\n",
    "    if \"ResNet\" in model_name: return res_preprocess\n",
    "    if \"Xception\" in model_name: return xcp_preprocess\n",
    "    \n",
    "    # Default (EfficientNet and others)\n",
    "    return eff_preprocess\n",
    "\n",
    "# --- 6. EVALUATION FUNCTION ---\n",
    "def evaluate_candidate(name, modality, test_df_data):\n",
    "    path = os.path.join(MODEL_DIR, f\"{name}.keras\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"   [Skipped] {name} not found.\")\n",
    "        return -1.0\n",
    "\n",
    "    print(f\"   Testing {name}...\", end=\"\")\n",
    "    try:\n",
    "        model = load_model(path, compile=False)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        pre_func = get_preprocess_func(name, modality) \n",
    "        \n",
    "        # Determine target size from model input\n",
    "        try:\n",
    "            input_shape = model.input_shape[1:]\n",
    "            target_size = (input_shape[0], input_shape[1])\n",
    "        except:\n",
    "            target_size = (224, 224) # Fallback\n",
    "        \n",
    "        if modality == \"AUDIO\":\n",
    "            gen = NpyDataGenerator(test_df_data, pre_func, BATCH_SIZE, target_size=target_size)\n",
    "        else:\n",
    "            datagen = ImageDataGenerator(preprocessing_function=pre_func)\n",
    "            gen = datagen.flow_from_dataframe(\n",
    "                test_df_data, x_col='face_path', y_col=label_column,\n",
    "                target_size=target_size, batch_size=BATCH_SIZE, \n",
    "                class_mode='categorical', shuffle=False, verbose=0\n",
    "            )\n",
    "            \n",
    "        loss, acc = model.evaluate(gen, verbose=0)\n",
    "        print(f\" Score: {acc*100:.2f}%\")\n",
    "        \n",
    "        # Cleanup to save memory\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        return acc\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {e}\")\n",
    "        return -1.0\n",
    "\n",
    "# --- 7. EXECUTION ---\n",
    "AUDIO_CANDIDATES = [\n",
    "    \"Audio_Baseline_CNN\", \n",
    "    \"Audio_ResNet50\", \n",
    "    \"Audio_CRNN_LSTM\", \n",
    "    \"Audio_EfficientNet_Refined\",\n",
    "    \"Audio_ResNet50_Augmented_Balanced\",\n",
    "    \"Audio_EfficientNet_Balanced\"\n",
    "]\n",
    "\n",
    "FACE_CANDIDATES = [\n",
    "    \"Face_Baseline_CNN\", \n",
    "    \"Face_Xception\", \n",
    "    \"Face_ResNet50\", \n",
    "    \"efficientnet_improved\",\n",
    "    \"Face_EfficientNet_Balanced\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- EVALUATING AUDIO MODELS ---\")\n",
    "best_audio_name = None; best_audio_score = -1.0\n",
    "for name in AUDIO_CANDIDATES:\n",
    "    score = evaluate_candidate(name, \"AUDIO\", test_aud)\n",
    "    if score > best_audio_score:\n",
    "        best_audio_score = score; best_audio_name = name\n",
    "\n",
    "print(\"\\n--- EVALUATING FACE MODELS ---\")\n",
    "best_face_name = None; best_face_score = -1.0\n",
    "for name in FACE_CANDIDATES:\n",
    "    score = evaluate_candidate(name, \"FACE\", test_df)\n",
    "    if score > best_face_score:\n",
    "        best_face_score = score; best_face_name = name\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
